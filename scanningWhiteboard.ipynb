{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scanning Whiteboard Contents\n",
    "\n",
    "## Final Project of Digital Image Processing course [SCC0251]\n",
    "\n",
    "This notebook contains the final report of an application developed as the final project of the Digital Image Processing course(SCC0251) at the Institute of Mathematics and Computer Science(ICMC-USP) by Prof. Moacir Ponti.\n",
    "\n",
    "### Students\n",
    "- David Souza Rodrigues;\n",
    "- Marcos Wendell Souza de Oliveira Santos;\n",
    "\n",
    "### Objective\n",
    "The goal of this application is the digitalization of whiteboard contents capture. This application locates the boundary of the whiteboard, rectifies the geometry distortion and corrects the non-uniform illumination.\n",
    "\n",
    "### Application Functionalities\n",
    "The application will read a whiteboard image, remove it's surroundings, centralize the whiteboard content and adjust image luminosity as to facilitate the comprehension of the image.\n",
    "\n",
    "### Images Source\n",
    "The application will be developed based on the images available on the Pantheon Project website, plus images captured by the students using black, blue, red and green markers while using flash on the camera.\n",
    "\n",
    "### Digital Images Processing Techniques\n",
    "1. Edges' detection: Using the differential filter with a convolution operation;\n",
    "2. Horizontal and Vertical lines' detection: A convolution with the proper filters may be used, as well as the Hough transform;\n",
    "3. Whiteboard's boundaries detection: Given the detected lines, identify the best possible match for the quadrilateral shape of the whitedoard's bounderies;\n",
    "4. Image's Geometry correction: Perform a 3D transformation to adjust the coordinates;\n",
    "5. Luminosity correction: Color enhancement to obtain a uniform background, removing light spots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application we will be using:\n",
    "- _numpy_ library to manipulate and compute with high-performance multidimensional arrays;\n",
    "- _imageio_ to read the input image;\n",
    "- _pyplot_ to show the images generated in each step of the program;\n",
    "- _scipy_ to apply the convolution operations;\n",
    "- _math_ for mathematical operations;\n",
    "- _cv2_ to find the quadragular region of the whiteboard and apply the homography method;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio\n",
    "from scipy.signal import convolve\n",
    "from math import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we start by reading the input image located in a specif file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File location:./images/whiteboard01.png\n"
     ]
    }
   ],
   "source": [
    "file = str(input(\"File location:\")).rstrip()\n",
    "image = iio.imread(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, a luminance operation is applied so we can obtain a gray-level image as result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = 0.299*image[:,:,0]+0.587*image[:,:,1]+0.114*image[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soon after, we generate and apply a Gaussian Filter to reduce the gray-level image noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, sigma = 3, 1.0\n",
    "arx = np.arange((-k//2)+1.0,(k//2)+1.0)\n",
    "x,y = np.meshgrid(arx,arx)\n",
    "filt = np.exp(-(1/2)*(np.square(x)+np.square(y))/np.square(sigma))\n",
    "gaussian_filter = filt/np.sum(filt)\n",
    "image2 = convolve(image1,gaussian_filter,'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, in order to find the edges of the objects on the image scene, we apply an horizontal and a vertical mask based on Sobel's filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "horizontal = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "image3 = np.absolute(convolve(image2,vertical,'valid'), 2) + np.absolute(convolve(image2,horizontal,'valid'), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we normalize the image in range [0,255] so that we can compare with a threshold later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMax = 255\n",
    "max, min = image3.max(), image3.min()\n",
    "image3 = newMax*((image3-min)/(max-min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold chosen by this application was determined only by the analysis of the normalized image obtained in the previous step and may vary according to the input image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tH = 15\n",
    "image4 = np.where(image3 >= tH, 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define some functions to deal with the line's detection, in this case, we'll be using Hough Transform technique to find the most outstanding lines(in our case, 5 lines). This technique purpose is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough Transform.\n",
    "\n",
    "A line can be represented as _y = mx+c_ or in parametric form, as _rho = x*cos(theta) + y*sin(theta)_, where rho is the perpendicular distance from origin to the line, and theta is the angle formed by this perpendicular line and horizontal axis measured in counter-clockwise.\n",
    "\n",
    "Hough Transform will use the _(rho,theta)_ space as parameter space so for each feature point in the image, put a vote in every bin in this space that could have generated this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HoughTransform(img,minAngle=-90.0,maxAngle=90.0):\n",
    "    M,N =  img.shape\n",
    "    dist_max = ceil(sqrt(M*M+N*N))\n",
    "    theta = np.deg2rad(np.arange(minAngle,maxAngle))\n",
    "    # dists = np.linspace(-dist_max,dist_max,dist_max*2)\n",
    "    hough = np.zeros((dist_max*2,len(theta)))\n",
    "    x,y = np.nonzero(img)\n",
    "    points = [[list()] * len(theta) for i in range(dist_max*2)]\n",
    "    newImage = np.zeros((img.shape))\n",
    "\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    aa = dist_max*2\n",
    "    for i in range(len(x)):\n",
    "        xa = x[i]\n",
    "        ya = y[i]\n",
    "        for t in range(len(theta)):\n",
    "            rho = int(round(xa*c[t] + ya*s[t]))+dist_max\n",
    "            if(rho < aa):\n",
    "                hough[rho,t] += 1\n",
    "                points[rho][t].append((xa,ya))\n",
    "    max = maxPoints(hough)\n",
    "    for x in range(dist_max*2):\n",
    "        for y in range(len(theta)):\n",
    "            if(hough[x][y] in max):\n",
    "                for z in points[x][y]:\n",
    "                    newImage[z[0]][z[1]] = 255\n",
    "    return newImage\n",
    "\n",
    "def maxPoints(hough, n=5):\n",
    "    flat = hough.flatten()\n",
    "    flat = np.flip(np.sort(flat))\n",
    "\n",
    "    max = []\n",
    "    for i in range(n):\n",
    "        max.append(flat[0])\n",
    "        idx = np.argwhere(flat==flat[0])\n",
    "        flat = np.delete(flat, idx)\n",
    "\n",
    "    return max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to apply the Hough Transform to the vertical lines, that is, 90 degrees, with a tolerance of 20 degrees upwards and downwards to compensate the angle's variation on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image5 = HoughTransform(image4,70.0,110.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apply it to the horizontal lines, that is, 0 degreees, with a tolerance of 20 degrees upwards and downwards as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image6 = HoughTransform(image4,-20.0,20.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join the results of both function calls in a single image and will obtain the 5 most outstanding vertical and horizontal lines highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image7 = image5 + image6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our application consists on finding the whiteboard's vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image8 = np.where(image7 > 0, 1, 0).astype('uint8')\n",
    "image8, contours = cv2.findContours(image8, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the set of vertices identified, we can apply a homography operation to perform a geometry correction on the image. For this step, we're also using an implemented fuction found on openCV library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N,_ = image.shape\n",
    "aux,b = cv2.findHomography(np.array(((102,128),(532,110),(553,428),(100,404))),np.array(((0,0),(N,0),(N,M),(0,M))))\n",
    "image9 = cv2.warpPerspective(image,aux,(N,M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in our application consists in a illumination correction on the image.\n",
    "\n",
    "For this, we are using a convertion to the HSL color space, due to it's specific lightness channel, which makes it easier to handle the analysis and modifications on the illumination aspects of our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsl = np.ndarray(img.shape)\n",
    "img = normalize(image9,1,image9.max()).astype(\"float\")\n",
    "image10 = np.ndarray(img.shape)\n",
    "\n",
    "for x in range(img.shape[0]):\n",
    "    for y in range(img.shape[1]):\n",
    "        #H\n",
    "        max = img[x][y].argmax()\n",
    "        min = img[x][y].argmin()\n",
    "        aux = img[x][y][max] - img[x][y][min]\n",
    "        if aux == 0:\n",
    "            hsl[x][y][0] = 0\n",
    "        elif max == 0:\n",
    "            hsl[x][y][0] = 60 *((img[x][y][1] - img[x][y][2])/aux)\n",
    "        elif max == 1:\n",
    "            hsl[x][y][0] = 60 *(2+((img[x][y][2] - img[x][y][0])/aux))\n",
    "        elif max == 2:\n",
    "            hsl[x][y][0] = 60 *(4+((img[x][y][0] - img[x][y][1])/aux))\n",
    "        if hsl[x][y][0] < 0:\n",
    "            hsl[x][y][0] += 360\n",
    "\n",
    "        # L\n",
    "        hsl[x][y][2] = (img[x][y][max]+img[x][y][min])/2\n",
    "\n",
    "        # S\n",
    "        if img[x][y][max] == 0 or img[x][y][min] == 1:\n",
    "            hsl[x][y][1] = 0\n",
    "        else:\n",
    "            hsl[x][y][1] = (2*img[x][y][max]-2*hsl[x][y][2])/(1-abs(2*hsl[x][y][2] - 1))\n",
    "\n",
    "mean = np.mean(hsl[:,:,2])\n",
    "background = np.where(hsl[:,:,2] < 0.68,hsl[:,:,2],mean)\n",
    "plt.figure('back')\n",
    "plt.imshow(background)\n",
    "hsl[:,:,2] = normalize(background,1,background.max())\n",
    "# hsl[:,:,2] = np.where(background != 0, (hsl[:,:,2] - background) + mean,hsl[:,:,2])\n",
    "plt.figure(\"hsl\")\n",
    "plt.imshow(hsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimatly, we just need to convert the image back to the RGB color space to obtain our result image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(img.shape[0]):\n",
    "    for y in range(img.shape[1]):\n",
    "        C = (1 - abs(2*hsl[x][y][2] - 1))*hsl[x][y][1]\n",
    "        H_ = hsl[x][y][0]/60\n",
    "        X = C*(1 - abs(H_ % 2 - 1))\n",
    "        m = hsl[x][y][2] - C/2\n",
    "        if 0 <= H_ and H_ <= 1:\n",
    "            image10[x][y] = np.array([C,X,0]) + m\n",
    "        elif 1 < H_ and H_ <= 2:\n",
    "            image10[x][y] = np.array([X,C,0]) + m\n",
    "        elif 2 < H_ and H_ <= 3:\n",
    "            image10[x][y] = np.array([0,C,X]) + m\n",
    "        elif 3 < H_ and H_ <= 4:\n",
    "            image10[x][y] = np.array([0,X,C]) + m\n",
    "        elif 4 < H_ and H_ <= 5:\n",
    "            image10[x][y] = np.array([X,0,C]) + m\n",
    "        elif 5 < H_ and H_ <= 6:\n",
    "            image10[x][y] = np.array([C,0,X]) + m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
